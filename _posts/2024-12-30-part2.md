## Part II: brains to bytes - journey from neurons to perceptrons

# inspo from biological neurons
imagine your brain as a bustling metropolis, with trillions of neurons playing the role of its inhabitants. <br>
these neurons are the ultimate multitaskers, constantly processing information, making decisions, and passing on messages.

hereâ€™s the deal:

***dendrites*** are like antennas, receiving signals from other neurons. 

***synapses*** are the connection points where neurons â€œtalkâ€ to each other. 

***soma*** processes the incoming signals, like a central office handling information. 

***axons*** transmit the processed signal to the next set of neurons.

![Diagram](https://miro.medium.com/v2/resize:fit:1400/1*K1ee1SzB0lxjIIo7CGI7LQ.png)

this interconnected network forms a hierarchy. at the base, neurons might detect simple edges or corners (think: your brain spotting the outline of a cat). <br>
higher up, they start combining this information to recognize patterns or even, say, a fluffy tail.

# meet the mcculloch pitts neuron - the first artificial brain cell
in 1943, warren mcculloch and walter pitts proposed a simplified computational model of a neuron. <br>
called the mcculloch pitts (MP) Neuron which laid the groundwork for modern neural networks.

the MP neuron isnâ€™t as fancy as its biological counterpart, but it does the job. 

hereâ€™s how it works:

- it takes a bunch of binary inputs (0s and 1s) from its environment. <br>
- each input can either excite or inhibit the neuron. <br>
- it aggregates these inputs using a function ğ‘”(ğ‘¥), which is essentially the sum of the inputs. <br>
- it compares this sum to a threshold ğœƒ.<br>
- if ğ‘”(ğ‘¥) >= ğœƒ, the neuron â€œfiresâ€ (output = 1).<br>
  otherwise, it stays quiet (output = 0).<br>


![diagram](https://miro.medium.com/v2/resize:fit:738/1*fDHlg9iNo0LLK4czQqqO9A.png)

![image](https://raw.githubusercontent.com/abhiruchipb/abhiruchipb.github.io/refs/heads/main/_posts/images/image4.png)

for example, if we fix a threshold ğœƒ = 3, the mp neuron fires only when atleast 3 of the xi's are 1.

this process is called ***thresholding logic***, and itâ€™s surprisingly powerful.

# Boolean Functions and the MP Neuron

An MP neuron has two main parts:
- ***Aggregation:*** The neuron sums its inputs, optionally weighted.<br>
- ***Thresholding:*** It outputs 1 if the sum exceeds a threshold value (Î¸), otherwise 0.<br>

Mathematically:
![image](https://raw.githubusercontent.com/abhiruchipb/abhiruchipb.github.io/refs/heads/main/_posts/Screenshot%202024-12-31%20020838.png)

Here:
ğ‘¥ğ‘– : Input values (0 or 1 for Boolean functions)
ğ‘¤ğ‘– : Weights (can be binary or real numbers)
ğœƒ : Threshold
