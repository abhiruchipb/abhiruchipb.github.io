## Part II: brains to bytes - journey from neurons to perceptrons

# inspo from biological neurons
imagine your brain as a bustling metropolis, with trillions of neurons playing the role of its inhabitants. 
these neurons are the ultimate multitaskers, constantly processing information, making decisions, and passing on messages.

here’s the deal:

**dendrites** are like antennas, receiving signals from other neurons. 

**synapses** are the connection points where neurons “talk” to each other. 

**soma** processes the incoming signals, like a central office handling information. 

**axons** transmit the processed signal to the next set of neurons.

![Diagram](https://miro.medium.com/v2/resize:fit:1400/1*K1ee1SzB0lxjIIo7CGI7LQ.png)

this interconnected network forms a hierarchy. at the base, neurons might detect simple edges or corners (think: your brain spotting the outline of a cat).
higher up, they start combining this information to recognize patterns or even, say, a fluffy tail.

# Meet the McCulloch Pitts Neuron: The First Artificial Brain Cell
Back in 1943, two brilliant minds—Warren McCulloch, a neuroscientist, and Walter Pitts, a logician—proposed a simplified computational model of a neuron. It was the birth of artificial neurons, and their creation, aptly named the McCulloch Pitts (MP) Neuron, laid the groundwork for modern neural networks.

The MP neuron isn’t as fancy as its biological counterpart, but it does the job. 

Here’s how it works:

It takes a bunch of binary inputs (0s and 1s) from its environment.
Each input can either excite or inhibit the neuron.
It aggregates these inputs using a function 𝑔(𝑥), which is essentially the sum of the inputs.
It compares this sum to a threshold 𝜃.
If 𝑔(𝑥) is greater than or equal to 𝜃, the neuron “fires” (output = 1).
Otherwise, it stays quiet (output = 0).
This process is called thresholding logic, and it’s surprisingly powerful.
